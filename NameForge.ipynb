{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# NameForge: AI Domain Name Generator Homework\n",
    "\n",
    "**Author:** Ferdinand Koenig\n",
    "**Date:** Sep 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook documents the AI Engineer homework assignment for building a domain name generator.\n",
    "Objectives:\n",
    "\n",
    "- Generate synthetic dataset of business descriptions → domain names\n",
    "- Build a baseline domain generator (mock / open-source LLM)\n",
    "- Implement evaluation framework (LLM-as-a-judge / safety checks)\n",
    "- Analyze edge cases and iteratively improve\n",
    "- Ensure safety guardrails for inappropriate content\n"
   ],
   "id": "5cc073c8f706f17e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:15:24.683998Z",
     "start_time": "2025-09-05T09:15:24.212188Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "bd48274984db08b6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1️⃣ Step: Synthetic Dataset Creation\n",
    "\n",
    "### 1.1 Methodology\n",
    "\n",
    "**Objective:**\n",
    "Generate a synthetic dataset of business descriptions mapped to domain names, with diversity in business types, complexity levels, and edge cases, while ensuring safety and reproducibility.\n",
    "\n",
    "**Steps Taken:**\n",
    "\n",
    "1. **Vocabulary Selection**\n",
    "   - **Business types:** cafe, restaurant, tech startup, online store, boutique, law firm, travel agency, bookstore, etc.\n",
    "   - **Adjectives / descriptors:** organic, eco-friendly, bright, cozy, modern, smart, fresh, premium, global, innovative\n",
    "   - **Nouns / themes:** hub, shop, store, lab, studio, solutions, works, spot, corner\n",
    "   - **TLDs:** .com, .net, .org, .io, .co\n",
    "   - Vocabulary is stored externally in `src/vocab.py` for maintainability and easy updates.\n",
    "\n",
    "2. **Complexity Levels**\n",
    "   - **Simple:** Short, straightforward descriptions → short domains (e.g., “Organic cafe”)\n",
    "   - **Medium:** Include location or moderate complexity (e.g., “Organic cafe in downtown area”)\n",
    "   - **Complex:** Long or multi-purpose descriptions (e.g., “Premium organic cafe in downtown area offering community events for busy professionals”)\n",
    "\n",
    "3. **Edge Cases**\n",
    "   - ~5% of entries include unusual or extreme cases:\n",
    "     - Extremely long business descriptions\n",
    "     - Very short or ambiguous descriptions\n",
    "     - Uncommon characters (e.g., symbols @$%^)\n",
    "   - These cases test model robustness and evaluation coverage.\n",
    "\n",
    "4. **Safety Guardrails**\n",
    "   - Forbidden words: `adult`, `nude`, `porn`, `illegal`\n",
    "   - Any generated domain containing forbidden words is replaced with `blocked.com`\n",
    "\n",
    "5. **Dataset Generation Process**\n",
    "   - Randomly combine adjectives, nouns, and business types according to complexity\n",
    "   - Assign complexity distribution: 40% simple, 40% medium, 20% complex\n",
    "   - Randomly insert edge cases\n",
    "   - Save datasets as CSV with fields: `business_description`, `domain_name`, `complexity`\n",
    "\n",
    "6. **Train/Test Split**\n",
    "   - Train dataset: 500 entries\n",
    "   - Test dataset: 100 entries\n",
    "   - Stored in `data/raw/` as `train_dataset.csv` and `test_dataset.csv`\n",
    "\n",
    "### 1.2 Practical Considerations\n",
    "\n",
    "- **Reflecting client needs:**\n",
    "  - The synthetic dataset is designed to mimic the examples provided in the homework task, ensuring generated domain names are relevant to realistic business descriptions.\n",
    "\n",
    "- **Resource efficiency:**\n",
    "  - No fine-tuned LLM is used at this stage due to GPU requirements.\n",
    "  - No external API calls (OpenAI, Claude, etc.) are used because free accounts may not have access or sufficient credits.\n",
    "\n",
    "- **Reproducibility:**\n",
    "  - Dataset generation relies on deterministic Python code with controlled randomness (`random` module).\n",
    "  - Vocabulary is externalized for maintainability (`src/vocab.py`).\n",
    "  - The process can be fully run on a standard laptop without specialized hardware.\n",
    "\n",
    "- **Edge cases and safety:**\n",
    "  - ~5% of entries are extreme or unusual to test model robustness.\n",
    "  - Safety guardrails ensure forbidden words are blocked.\n",
    "\n"
   ],
   "id": "1dd0965a5267c931"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T11:09:20.116242Z",
     "start_time": "2025-09-06T11:09:20.034994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.data_utils import generate_train_test\n",
    "\n",
    "generate_train_test(train_size=3_000, test_size=100)"
   ],
   "id": "718228688be801a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating 3000 entries\n",
      "Dataset generated at data/raw/train_dataset.csv with 3000 entries\n",
      "generating 100 entries\n",
      "Dataset generated at data/raw/test_dataset.csv with 100 entries\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "470d02069181a1ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
